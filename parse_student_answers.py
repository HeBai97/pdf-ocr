from transformers import AutoModel, AutoTokenizer
import torch
import os
from PIL import Image
import sys
from io import StringIO
import re
import tempfile
import numpy as np
from reportlab.pdfgen import canvas
from reportlab.pdfbase import pdfmetrics
from reportlab.pdfbase.ttfonts import TTFont

# å°è¯•å¯¼å…¥IPEX
try:
    import intel_extension_for_pytorch as ipex
    ipex_available = True
except (ImportError, OSError) as e:
    ipex_available = False
    print(f"IPEXä¸å¯ç”¨: {type(e).__name__}")

# å°è¯•å¯¼å…¥pytesseractç”¨äºå¿«é€Ÿæ–¹å‘æ£€æµ‹
try:
    import pytesseract
    tesseract_available = True
except ImportError:
    tesseract_available = False
    print("pytesseractä¸å¯ç”¨ï¼Œå°†ä½¿ç”¨ä¼ ç»Ÿçš„4æ¬¡æ—‹è½¬å°è¯•æ–¹æ³•")

# å°è¯•ä½¿ç”¨XPUï¼ˆIntel Arcï¼‰ï¼Œå¦‚æœä¸å¯ç”¨åˆ™ä½¿ç”¨CPU
if hasattr(torch, 'xpu') and torch.xpu.is_available():
    device = 'xpu'
    print(f"ä½¿ç”¨Intel XPU: {torch.xpu.get_device_name(0)}")
    if not ipex_available:
        print("è­¦å‘Š: IPEXæœªå®‰è£…ï¼Œæ€§èƒ½å¯èƒ½å—å½±å“")
else:
    device = 'cpu'
    print("XPUä¸å¯ç”¨ï¼Œä½¿ç”¨CPUæ¨¡å¼")

# å¿«é€Ÿæ£€æµ‹å›¾ç‰‡æ–¹å‘ï¼ˆä½¿ç”¨Tesseract OSDï¼‰
def detect_orientation_fast(image_path):
    """ä½¿ç”¨Tesseractå¿«é€Ÿæ£€æµ‹å›¾ç‰‡æ–¹å‘ï¼ˆæ¯«ç§’çº§ï¼‰"""
    if not tesseract_available:
        return None
    
    try:
        image = Image.open(image_path)
        
        # ä½¿ç”¨Tesseractçš„OSDï¼ˆOrientation and Script Detectionï¼‰
        osd = pytesseract.image_to_osd(image, output_type=pytesseract.Output.DICT)
        
        rotation = osd.get('rotate', 0)  # éœ€è¦æ—‹è½¬çš„è§’åº¦
        confidence = osd.get('orientation_conf', 0)  # ç½®ä¿¡åº¦
        
        print(f"  â†’ Tesseractæ£€æµ‹: éœ€è¦æ—‹è½¬ {rotation}åº¦ (ç½®ä¿¡åº¦: {confidence:.2f})")
        
        # å¦‚æœç½®ä¿¡åº¦è¾ƒé«˜ï¼Œè¿”å›æ£€æµ‹ç»“æœ
        if confidence > 1.0:  # Tesseractçš„ç½®ä¿¡åº¦é˜ˆå€¼
            return rotation
        else:
            print(f"  â†’ ç½®ä¿¡åº¦è¾ƒä½ï¼Œå°†å°è¯•æ‰€æœ‰è§’åº¦")
            return None
            
    except Exception as e:
        print(f"  â†’ Tesseractæ£€æµ‹å¤±è´¥: {e}")
        return None

# ä»EXIFè·å–æ–¹å‘ä¿¡æ¯
def get_exif_orientation(image_path):
    """ä»å›¾ç‰‡EXIFæ•°æ®è·å–æ–¹å‘ä¿¡æ¯ï¼ˆæœ€å¿«ï¼‰"""
    try:
        from PIL.ExifTags import TAGS
        image = Image.open(image_path)
        exif = image._getexif()
        
        if exif:
            for tag_id, value in exif.items():
                tag = TAGS.get(tag_id, tag_id)
                if tag == 'Orientation':
                    # EXIF orientationå€¼æ˜ å°„
                    orientation_map = {1: 0, 3: 180, 6: 270, 8: 90}
                    rotation = orientation_map.get(value, 0)
                    if rotation != 0:
                        print(f"  â†’ EXIFæ–¹å‘: éœ€è¦æ—‹è½¬ {rotation}åº¦")
                        return rotation
    except:
        pass
    
    return None

# æ™ºèƒ½æ£€æµ‹å›¾ç‰‡æ–¹å‘ï¼ˆç»„åˆå¤šç§æ–¹æ³•ï¼‰
def smart_detect_orientation(image_path):
    """æ™ºèƒ½æ£€æµ‹å›¾ç‰‡æ–¹å‘ï¼Œè¿”å›éœ€è¦æ—‹è½¬çš„è§’åº¦"""
    print("ğŸ” æ­£åœ¨å¿«é€Ÿæ£€æµ‹å›¾ç‰‡æ–¹å‘...")
    
    # æ–¹æ³•1: æ£€æŸ¥EXIFä¿¡æ¯ï¼ˆç¬æ—¶ï¼‰
    exif_rotation = get_exif_orientation(image_path)
    if exif_rotation is not None:
        return exif_rotation
    
    # æ–¹æ³•2: ä½¿ç”¨Tesseract OSDï¼ˆæ¯«ç§’çº§ï¼‰
    tesseract_rotation = detect_orientation_fast(image_path)
    if tesseract_rotation is not None:
        return tesseract_rotation
    
    # å¦‚æœæ‰€æœ‰å¿«é€Ÿæ–¹æ³•éƒ½å¤±è´¥ï¼Œè¿”å›Noneï¼ˆä½¿ç”¨å›é€€æ–¹æ¡ˆï¼‰
    print("  â†’ å¿«é€Ÿæ£€æµ‹æœªæˆåŠŸï¼Œå°†å°è¯•æ‰€æœ‰æ—‹è½¬è§’åº¦")
    return None

# æ¸…ç†OCRè¾“å‡ºæ–‡æœ¬çš„å‡½æ•°
def clean_ocr_output(text):
    """æ¸…ç†OCRè¾“å‡ºï¼Œç§»é™¤ç‰¹æ®Šæ ‡è®°"""
    if not text:
        return ""
    
    # ç§»é™¤ <|ref|>...<|/ref|> æ ‡è®°
    text = re.sub(r'<\|ref\|>.*?<\|/ref\|>', '', text)
    # ç§»é™¤ <|det|>...<|/det|> æ ‡è®°ï¼ˆåŒ…å«åæ ‡ï¼‰
    text = re.sub(r'<\|det\|>.*?<\|/det\|>', '', text)
    # ç§»é™¤å¤šä½™çš„ç©ºè¡Œ
    text = re.sub(r'\n\s*\n\s*\n', '\n\n', text)
    # ç§»é™¤å¼€å¤´å’Œç»“å°¾çš„ç©ºç™½
    text = text.strip()
    
    return text

# å°è¯•ä¸åŒè§’åº¦æ—‹è½¬å›¾ç‰‡
def try_rotate_image(image_path):
    """å°è¯•ä¸åŒè§’åº¦æ—‹è½¬å›¾ç‰‡ï¼Œè¿”å›å¯èƒ½çš„æ—‹è½¬ç‰ˆæœ¬"""
    img = Image.open(image_path)
    
    # è¿”å›åŸå›¾å’Œ3ä¸ªæ—‹è½¬ç‰ˆæœ¬ï¼ˆ90åº¦ã€180åº¦ã€270åº¦ï¼‰
    rotations = {
        '0åº¦': img,
        '90åº¦': img.rotate(-90, expand=True),
        '180åº¦': img.rotate(180, expand=True),
        '270åº¦': img.rotate(-270, expand=True)
    }
    
    return rotations

# åŠ è½½DeepSeek-OCRæ¨¡å‹
model_name = 'deepseek-ai/DeepSeek-OCR'

print("æ­£åœ¨åŠ è½½æ¨¡å‹...")
tokenizer = AutoTokenizer.from_pretrained(model_name, trust_remote_code=True)

# å¯¹äºArcæ˜¾å¡ï¼Œä¸ä½¿ç”¨flash_attention_2ï¼Œä½¿ç”¨é»˜è®¤çš„attention
if device == 'xpu':
    model = AutoModel.from_pretrained(
        model_name, 
        trust_remote_code=True, 
        use_safetensors=True,
        torch_dtype=torch.bfloat16
    )
    model = model.eval()
    model = model.to('xpu')
    # ä½¿ç”¨IPEXä¼˜åŒ–ï¼ˆå¦‚æœå¯ç”¨ï¼‰
    if ipex_available:
        model = ipex.optimize(model, dtype=torch.bfloat16)
        print("å·²å¯ç”¨IPEXä¼˜åŒ–")
else:
    # CPUæ¨¡å¼ï¼šä½¿ç”¨float32ä»¥é¿å…dtypeä¸åŒ¹é…é—®é¢˜
    model = AutoModel.from_pretrained(
        model_name, 
        trust_remote_code=True, 
        use_safetensors=True,
        torch_dtype=torch.float32
    )
    model = model.eval()
    model = model.to('cpu')
    # ç¡®ä¿æ‰€æœ‰å‚æ•°éƒ½æ˜¯float32
    model = model.float()

print("æ¨¡å‹åŠ è½½å®Œæˆï¼")

# ==================== åŒå±‚PDFç”Ÿæˆå™¨ ====================
class DoubleLayerPDFGenerator:
    """ä½¿ç”¨ DeepSeek-OCR ç”ŸæˆåŒå±‚PDFï¼ˆåº•å±‚å›¾åƒ + ä¸Šå±‚é€æ˜å¯æœç´¢æ–‡æœ¬ï¼‰"""
    
    def __init__(self, model, tokenizer, device):
        """
        åˆå§‹åŒ–åŒå±‚PDFç”Ÿæˆå™¨
        
        Args:
            model: DeepSeek-OCR æ¨¡å‹å®ä¾‹
            tokenizer: DeepSeek-OCR tokenizer
            device: è¿è¡Œè®¾å¤‡ ('xpu' æˆ– 'cpu')
        """
        self.model = model
        self.tokenizer = tokenizer
        self.device = device
        self.font_name = "Helvetica"  # é»˜è®¤å­—ä½“
        self.dpi = 300
        
        # å°è¯•æ³¨å†Œä¸­æ–‡å­—ä½“
        try:
            # å°è¯•å¸¸è§çš„ä¸­æ–‡å­—ä½“è·¯å¾„
            font_paths = [
                "C:/Windows/Fonts/msyh.ttc",  # Windows å¾®è½¯é›…é»‘
                "C:/Windows/Fonts/simsun.ttc",  # Windows å®‹ä½“
                "/usr/share/fonts/truetype/droid/DroidSansFallbackFull.ttf",  # Linux
                "/System/Library/Fonts/PingFang.ttc",  # macOS
            ]
            
            for font_path in font_paths:
                if os.path.exists(font_path):
                    pdfmetrics.registerFont(TTFont("ChineseFont", font_path))
                    self.font_name = "ChineseFont"
                    print(f"âœ“ å·²åŠ è½½ä¸­æ–‡å­—ä½“: {font_path}")
                    break
            else:
                print("âš  æœªæ‰¾åˆ°ä¸­æ–‡å­—ä½“ï¼Œä½¿ç”¨é»˜è®¤å­—ä½“ï¼ˆå¯èƒ½æ— æ³•æ˜¾ç¤ºä¸­æ–‡ï¼‰")
        except Exception as e:
            print(f"âš  å­—ä½“åŠ è½½å¤±è´¥: {e}ï¼Œä½¿ç”¨é»˜è®¤å­—ä½“")
    
    def ocr_image_with_boxes(self, image_path):
        """
        å¯¹å›¾ç‰‡æ‰§è¡ŒOCRå¹¶è¿”å›å¸¦ä½ç½®ä¿¡æ¯çš„ç»“æœ
        
        Returns:
            tuple: (texts, boxes) - æ–‡æœ¬åˆ—è¡¨å’Œå¯¹åº”çš„è¾¹ç•Œæ¡†åæ ‡
        """
        prompt = "<image>\n<|grounding|>Convert the document to markdown. "
        
        # æ•è· stdout
        old_stdout = sys.stdout
        sys.stdout = captured_output = StringIO()
        
        try:
            # æ‰§è¡ŒOCRï¼ˆå¯ç”¨groundingä»¥è·å–ä½ç½®ä¿¡æ¯ï¼‰
            res = self.model.infer(
                self.tokenizer,
                prompt=prompt,
                image_file=image_path,
                output_path='./',
                base_size=1024,
                image_size=1024,
                crop_mode=False,
                save_results=False,
                test_compress=True
            )
        finally:
            sys.stdout = old_stdout
        
        # è·å–è¾“å‡ºæ–‡æœ¬
        captured_text = captured_output.getvalue()
        
        # è§£ææ–‡æœ¬å’Œåæ ‡
        texts, boxes = self.parse_grounding_output(captured_text)
        
        return texts, boxes
    
    def parse_grounding_output(self, ocr_output):
        """
        è§£æ DeepSeek-OCR çš„ grounding è¾“å‡ºï¼Œæå–æ–‡æœ¬å’Œåæ ‡
        
        DeepSeek-OCR çš„è¾“å‡ºæ ¼å¼ç±»ä¼¼ï¼š
        <|det|>x1,y1,x2,y2,x3,y3,x4,y4<|/det|>æ–‡æœ¬å†…å®¹
        """
        texts = []
        boxes = []
        
        # æ­£åˆ™è¡¨è¾¾å¼åŒ¹é… <|det|>åæ ‡<|/det|>æ–‡æœ¬ æ¨¡å¼
        pattern = r'<\|det\|>([\d,]+)<\|/det\|>([^\n<]+)'
        matches = re.finditer(pattern, ocr_output)
        
        for match in matches:
            coords_str = match.group(1)
            text = match.group(2).strip()
            
            if not text:
                continue
            
            try:
                # è§£æåæ ‡ (x1,y1,x2,y2,x3,y3,x4,y4)
                coords = [float(x) for x in coords_str.split(',')]
                if len(coords) == 8:
                    # è½¬æ¢ä¸ºå››ä¸ªç‚¹çš„æ ¼å¼
                    box = [
                        [coords[0], coords[1]],  # å·¦ä¸Š
                        [coords[2], coords[3]],  # å³ä¸Š
                        [coords[4], coords[5]],  # å³ä¸‹
                        [coords[6], coords[7]]   # å·¦ä¸‹
                    ]
                    texts.append(text)
                    boxes.append(box)
            except (ValueError, IndexError) as e:
                print(f"âš  åæ ‡è§£æå¤±è´¥: {e}")
                continue
        
        print(f"âœ“ è§£æåˆ° {len(texts)} ä¸ªæ–‡æœ¬æ¡†")
        return texts, boxes
    
    def generate_double_layer_pdf(self, image_paths, output_pdf_path):
        """
        ç”ŸæˆåŒå±‚PDF
        
        Args:
            image_paths: å›¾ç‰‡è·¯å¾„åˆ—è¡¨ï¼ˆæ¯é¡µä¸€å¼ å›¾ï¼‰
            output_pdf_path: è¾“å‡ºPDFè·¯å¾„
        """
        if not image_paths:
            print("âŒ æ²¡æœ‰è¦å¤„ç†çš„å›¾ç‰‡")
            return False
        
        print(f"\n{'='*60}")
        print("å¼€å§‹ç”ŸæˆåŒå±‚PDF...")
        print(f"{'='*60}")
        
        c = canvas.Canvas(output_pdf_path)
        
        for page_num, img_path in enumerate(image_paths, 1):
            print(f"\næ­£åœ¨å¤„ç†ç¬¬ {page_num}/{len(image_paths)} é¡µ...")
            
            # æ‰“å¼€å›¾ç‰‡
            with Image.open(img_path) as img:
                img_width, img_height = img.size
                print(f"  å›¾ç‰‡å°ºå¯¸: {img_width} x {img_height}")
                
                # è®¾ç½®PDFé¡µé¢å°ºå¯¸
                c.setPageSize((img_width, img_height))
                
                # ç»˜åˆ¶åº•å±‚å›¾åƒ
                c.drawImage(img_path, 0, 0, width=img_width, height=img_height)
                print(f"  âœ“ å·²æ·»åŠ åº•å±‚å›¾åƒ")
                
                # æ‰§è¡ŒOCRè·å–æ–‡æœ¬å’Œä½ç½®
                print(f"  æ­£åœ¨æ‰§è¡ŒOCRè¯†åˆ«...")
                texts, boxes = self.ocr_image_with_boxes(img_path)
                
                # ç»˜åˆ¶é€æ˜æ–‡æœ¬å±‚
                if texts and boxes:
                    print(f"  æ­£åœ¨æ·»åŠ  {len(texts)} ä¸ªæ–‡æœ¬æ¡†...")
                    for text, box in zip(texts, boxes):
                        self.draw_transparent_text(c, text, box, img_height)
                    print(f"  âœ“ å·²æ·»åŠ é€æ˜æ–‡æœ¬å±‚")
                else:
                    print(f"  âš  è¯¥é¡µæ²¡æœ‰è¯†åˆ«åˆ°æ–‡æœ¬")
                
                # å®Œæˆå½“å‰é¡µ
                c.showPage()
        
        # ä¿å­˜PDF
        c.save()
        print(f"\n{'='*60}")
        print(f"âœ“ åŒå±‚PDFå·²ç”Ÿæˆ: {output_pdf_path}")
        print(f"{'='*60}")
        return True
    
    def draw_transparent_text(self, c, text, box, img_height):
        """
        åœ¨PDFä¸Šç»˜åˆ¶é€æ˜æ–‡æœ¬ï¼ˆä»…ç”¨äºæœç´¢ï¼Œä¸å¯è§ï¼‰
        
        Args:
            c: ReportLab canvaså¯¹è±¡
            text: è¦ç»˜åˆ¶çš„æ–‡æœ¬
            box: è¾¹ç•Œæ¡†åæ ‡ [[x1,y1], [x2,y2], [x3,y3], [x4,y4]]
            img_height: å›¾ç‰‡é«˜åº¦ï¼ˆç”¨äºYè½´åæ ‡è½¬æ¢ï¼‰
        """
        if not text or len(box) < 4:
            return
        
        # æå–è¾¹ç•Œæ¡†åæ ‡
        x_coords = [pt[0] for pt in box]
        y_coords = [pt[1] for pt in box]
        
        # è®¡ç®—è¾¹ç•Œæ¡†
        min_x = min(x_coords)
        max_x = max(x_coords)
        min_y = min(y_coords)
        max_y = max(y_coords)
        
        # PDFåæ ‡ç³»ç»Ÿï¼šYè½´ä»åº•éƒ¨å‘ä¸Šï¼Œéœ€è¦ç¿»è½¬
        pdf_min_y = img_height - max_y
        pdf_max_y = img_height - min_y
        
        box_width = max_x - min_x
        box_height = pdf_max_y - pdf_min_y
        
        if box_width <= 0 or box_height <= 0:
            return
        
        # è®¡ç®—å­—ä½“å¤§å°
        font_size = self.calculate_font_size(c, text, box_width, box_height)
        
        # è®¡ç®—æ–‡æœ¬ä½ç½®ï¼ˆå‚ç›´å±…ä¸­ï¼‰
        text_x = min_x
        text_y = pdf_min_y + (box_height - font_size) / 2
        
        # ç»˜åˆ¶é€æ˜æ–‡æœ¬ï¼ˆrenderMode=3: ä¸ç»˜åˆ¶å›¾å½¢ï¼Œåªä¿ç•™æ–‡æœ¬ç´¢å¼•ç”¨äºæœç´¢ï¼‰
        text_obj = c.beginText()
        text_obj.setTextRenderMode(3)  # ä¸å¯è§ä½†å¯æœç´¢
        text_obj.setFont(self.font_name, font_size)
        text_obj.setTextOrigin(text_x, text_y)
        
        # è®¡ç®—å­—ç¬¦é—´è·ä»¥å¡«å……å®½åº¦
        text_width = c.stringWidth(text, self.font_name, font_size)
        if len(text) > 1 and text_width < box_width:
            extra_space = (box_width - text_width) / (len(text) - 1)
            text_obj.setCharSpace(extra_space)
        
        text_obj.textLine(text)
        c.drawText(text_obj)
    
    def calculate_font_size(self, c, text, box_width, box_height):
        """
        è‡ªé€‚åº”è®¡ç®—å­—ä½“å¤§å°
        
        Args:
            c: ReportLab canvaså¯¹è±¡
            text: æ–‡æœ¬å†…å®¹
            box_width: è¾¹ç•Œæ¡†å®½åº¦
            box_height: è¾¹ç•Œæ¡†é«˜åº¦
        
        Returns:
            float: åˆé€‚çš„å­—ä½“å¤§å°
        """
        if not text:
            return 8
        
        # åŸºäºé«˜åº¦çš„å­—ä½“å¤§å°
        font_size_h = box_height * 0.9
        
        # åŸºäºå®½åº¦çš„å­—ä½“å¤§å°
        try:
            text_width = c.stringWidth(text, self.font_name, font_size_h)
            if text_width > 0:
                scale_ratio = box_width / text_width
                font_size_w = font_size_h * scale_ratio
            else:
                font_size_w = font_size_h
        except Exception:
            # ä¼°ç®—ï¼šå¹³å‡æ¯ä¸ªå­—ç¬¦å®½åº¦ä¸ºå­—ä½“å¤§å°çš„0.55å€
            avg_char_width = 0.55
            font_size_w = box_width / max(len(text), 1) / avg_char_width
        
        # å–ä¸¤è€…è¾ƒå°å€¼
        font_size = min(font_size_h, font_size_w)
        
        # é™åˆ¶åœ¨åˆç†èŒƒå›´å†…
        font_size = max(6, min(48, font_size))
        
        return round(font_size)

# åˆ›å»ºå…¨å±€PDFç”Ÿæˆå™¨å®ä¾‹
pdf_generator = DoubleLayerPDFGenerator(model, tokenizer, device)

# æ‰§è¡Œå•æ¬¡OCRè¯†åˆ«
def run_single_ocr(image_path, rotation_angle=0, save_name=None):
    """å¯¹å•å¼ å›¾ç‰‡æ‰§è¡Œä¸€æ¬¡OCRè¯†åˆ«"""
    import time
    import shutil
    
    # æ‰“å¼€å¹¶æ—‹è½¬å›¾ç‰‡
    img = Image.open(image_path)
    if rotation_angle == 90:
        img = img.rotate(-90, expand=True)
    elif rotation_angle == 180:
        img = img.rotate(180, expand=True)
    elif rotation_angle == 270:
        img = img.rotate(-270, expand=True)
    
    # ä¿å­˜ä¸´æ—¶å›¾ç‰‡
    temp_path = "temp_ocr_image.png"
    img.save(temp_path)
    
    prompt = "<image>\n<|grounding|>Convert the document to markdown. "
    start_time = time.time()
    
    # æ•è· stdout æ¥è·å–æ¨¡å‹è¾“å‡º
    old_stdout = sys.stdout
    sys.stdout = captured_output = StringIO()
    
    try:
        # æ‰§è¡ŒOCR
        res = model.infer(
            tokenizer, 
            prompt=prompt, 
            image_file=temp_path, 
            output_path='./', 
            base_size=1024,
            image_size=1024, 
            crop_mode=False,
            save_results=False,
            test_compress=True
        )
    finally:
        # æ¢å¤ stdout
        sys.stdout = old_stdout
    
    # è·å–æ•è·çš„è¾“å‡º
    captured_text = captured_output.getvalue()
    
    # æ¸…ç†è¾“å‡ºæ–‡æœ¬
    cleaned_text = clean_ocr_output(captured_text)
    
    elapsed_time = time.time() - start_time
    
    # ä¿å­˜å¤„ç†åçš„å›¾ç‰‡åˆ°imagesæ–‡ä»¶å¤¹
    if save_name:
        os.makedirs('images', exist_ok=True)
        save_path = os.path.join('images', f"{save_name}_{rotation_angle}åº¦.png")
        shutil.copy(temp_path, save_path)
        print(f"  â†’ å·²ä¿å­˜å›¾ç‰‡: {save_path}")
    
    # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
    if os.path.exists(temp_path):
        os.remove(temp_path)
    
    return cleaned_text, elapsed_time

# å¤„ç†å•å¼ å›¾ç‰‡çš„å‡½æ•°ï¼ˆä¼˜åŒ–ç‰ˆï¼‰
def process_image(image_path, output_name):
    """å¤„ç†å•å¼ å›¾ç‰‡ï¼Œæ™ºèƒ½æ£€æµ‹æ–¹å‘åæ‰§è¡ŒOCR"""
    print(f"\n{'='*60}")
    print(f"æ­£åœ¨å¤„ç†å›¾ç‰‡: {image_path}")
    print('='*60)
    
    import time
    
    # å°è¯•å¿«é€Ÿæ£€æµ‹å›¾ç‰‡æ–¹å‘
    detected_rotation = smart_detect_orientation(image_path)
    
    if detected_rotation is not None:
        # å¿«é€Ÿæ£€æµ‹æˆåŠŸï¼Œåªå¯¹æ£€æµ‹åˆ°çš„è§’åº¦æ‰§è¡Œä¸€æ¬¡OCR
        print(f"\nâœ… ä½¿ç”¨æ£€æµ‹åˆ°çš„æ–¹å‘: {detected_rotation}åº¦")
        print(f"âš¡ æ‰§è¡Œå•æ¬¡OCRè¯†åˆ«...")
        
        result_text, elapsed = run_single_ocr(image_path, detected_rotation, save_name=output_name)
        
        print(f"âœ“ è¯†åˆ«å®Œæˆï¼è€—æ—¶: {elapsed:.2f} ç§’, æ–‡æœ¬é•¿åº¦: {len(result_text)} å­—ç¬¦")
        
        # è½¬æ¢è§’åº¦åç§°
        rotation_map = {0: '0åº¦', 90: '90åº¦', 180: '180åº¦', 270: '270åº¦'}
        rotation_name = rotation_map.get(detected_rotation, '0åº¦')
        
        return result_text, rotation_name
    
    else:
        # å¿«é€Ÿæ£€æµ‹å¤±è´¥ï¼Œå›é€€åˆ°ä¼ ç»Ÿçš„4æ¬¡æ—‹è½¬å°è¯•æ–¹æ³•
        print(f"\nâš ï¸  å›é€€åˆ°ä¼ ç»Ÿæ–¹æ³•: å°è¯•æ‰€æœ‰æ—‹è½¬è§’åº¦...")
        
        # è·å–ä¸åŒæ—‹è½¬è§’åº¦çš„å›¾ç‰‡
        rotations = try_rotate_image(image_path)
        
        best_result = None
        best_length = 0
        best_rotation = None
        
        prompt = "<image>\n<|grounding|>Convert the document to markdown. "
        temp_folder = "temp_rotations"
        os.makedirs(temp_folder, exist_ok=True)
        os.makedirs('images', exist_ok=True)
        
        # å°è¯•ä¸åŒçš„æ—‹è½¬è§’åº¦
        for rotation_name, rotated_img in rotations.items():
            print(f"\nå°è¯• {rotation_name} æ—‹è½¬...")
            
            # ä¿å­˜ä¸´æ—¶æ—‹è½¬å›¾ç‰‡
            temp_path = os.path.join(temp_folder, f"temp_{rotation_name}.png")
            rotated_img.save(temp_path)
            
            # ä¿å­˜åˆ°imagesæ–‡ä»¶å¤¹ç”¨äºäºŒæ¬¡æ ¡éªŒ
            save_path = os.path.join('images', f"{output_name}_{rotation_name}.png")
            rotated_img.save(save_path)
            
            start_time = time.time()
            
            # æ•è· stdout æ¥è·å–æ¨¡å‹è¾“å‡º
            old_stdout = sys.stdout
            sys.stdout = captured_output = StringIO()
            
            try:
                # æ‰§è¡ŒOCR
                res = model.infer(
                    tokenizer, 
                    prompt=prompt, 
                    image_file=temp_path, 
                    output_path='./', 
                    base_size=1024,
                    image_size=1024, 
                    crop_mode=False,
                    save_results=False,
                    test_compress=True
                )
            finally:
                # æ¢å¤ stdout
                sys.stdout = old_stdout
            
            # è·å–æ•è·çš„è¾“å‡º
            captured_text = captured_output.getvalue()
            
            # æ¸…ç†è¾“å‡ºæ–‡æœ¬
            cleaned_text = clean_ocr_output(captured_text)
            
            elapsed_time = time.time() - start_time
            print(f"è¯†åˆ«è€—æ—¶: {elapsed_time:.2f} ç§’, æ–‡æœ¬é•¿åº¦: {len(cleaned_text)} å­—ç¬¦")
            print(f"  â†’ å·²ä¿å­˜å›¾ç‰‡: {save_path}")
            
            # é€‰æ‹©è¯†åˆ«æ–‡æœ¬æœ€é•¿çš„ç»“æœï¼ˆé€šå¸¸æ–‡æœ¬æœ€é•¿è¯´æ˜è¯†åˆ«æ•ˆæœæœ€å¥½ï¼‰
            if len(cleaned_text) > best_length:
                best_length = len(cleaned_text)
                best_result = cleaned_text
                best_rotation = rotation_name
        
        # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
        import shutil
        if os.path.exists(temp_folder):
            shutil.rmtree(temp_folder)
        
        print(f"\nâœ“ æœ€ä½³æ—‹è½¬è§’åº¦: {best_rotation}, æ–‡æœ¬é•¿åº¦: {best_length} å­—ç¬¦")
        
        return best_result, best_rotation

# ==================== ä¾¿æ·å‡½æ•°ï¼šç›´æ¥ç”ŸæˆåŒå±‚PDF ====================
def generate_pdf_from_images(image_paths, output_pdf_path='output_searchable.pdf'):
    """
    ä¾¿æ·å‡½æ•°ï¼šç›´æ¥ä»å›¾ç‰‡åˆ—è¡¨ç”ŸæˆåŒå±‚PDF
    
    Args:
        image_paths: å›¾ç‰‡è·¯å¾„åˆ—è¡¨ï¼ˆå­—ç¬¦ä¸²åˆ—è¡¨ï¼‰
        output_pdf_path: è¾“å‡ºPDFè·¯å¾„
    
    Returns:
        bool: æ˜¯å¦æˆåŠŸ
    
    ä½¿ç”¨ç¤ºä¾‹:
        # æ–¹å¼1: ä»æ–‡ä»¶åˆ—è¡¨ç”Ÿæˆ
        generate_pdf_from_images([
            '48b9bb8b3bef55124e97520838d68ce1.jpg',
            '8513578d2d071e55893ef0d9f36ba232.jpg'
        ], 'student_answers.pdf')
        
        # æ–¹å¼2: ä»imagesæ–‡ä»¶å¤¹ä¸­å·²å¤„ç†çš„å›¾ç‰‡ç”Ÿæˆ
        import glob
        processed_images = sorted(glob.glob('images/*.png'))
        generate_pdf_from_images(processed_images, 'output.pdf')
    """
    print(f"\n{'='*60}")
    print("ä½¿ç”¨ä¾¿æ·å‡½æ•°ç”ŸæˆåŒå±‚PDF")
    print(f"{'='*60}")
    print(f"è¾“å…¥å›¾ç‰‡æ•°é‡: {len(image_paths)}")
    print(f"è¾“å‡ºPDFè·¯å¾„: {output_pdf_path}")
    
    # æ£€æŸ¥å›¾ç‰‡æ˜¯å¦å­˜åœ¨
    valid_paths = []
    for img_path in image_paths:
        if os.path.exists(img_path):
            valid_paths.append(img_path)
            print(f"  âœ“ {img_path}")
        else:
            print(f"  âœ— {img_path} (ä¸å­˜åœ¨)")
    
    if not valid_paths:
        print("\nâŒ æ²¡æœ‰æœ‰æ•ˆçš„å›¾ç‰‡æ–‡ä»¶ï¼")
        return False
    
    print(f"\næ‰¾åˆ° {len(valid_paths)} ä¸ªæœ‰æ•ˆå›¾ç‰‡æ–‡ä»¶")
    
    # ç”ŸæˆPDF
    return pdf_generator.generate_double_layer_pdf(valid_paths, output_pdf_path)

# ä¸»ç¨‹åº
if __name__ == "__main__":
    # è¦å¤„ç†çš„å›¾ç‰‡åˆ—è¡¨
    images = [
        ("48b9bb8b3bef55124e97520838d68ce1.jpg", "å­¦ç”Ÿç­”å·_ç¬¬1å¼ "),
        ("8513578d2d071e55893ef0d9f36ba232.jpg", "å­¦ç”Ÿç­”å·_ç¬¬2å¼ ")
    ]
    
    all_results = []
    
    for image_path, name in images:
        if os.path.exists(image_path):
            result, rotation = process_image(image_path, name)
            all_results.append({
                'name': name,
                'path': image_path,
                'rotation': rotation,
                'content': result
            })
        else:
            print(f"è­¦å‘Š: å›¾ç‰‡æ–‡ä»¶ä¸å­˜åœ¨ - {image_path}")
    
    # ä¿å­˜ç»“æœåˆ°Markdown
    output_md = 'student_answers_output.md'
    
    with open(output_md, 'w', encoding='utf-8') as f:
        for idx, result in enumerate(all_results, 1):
            f.write(result['content'])
    
    print(f"\n{'='*60}")
    print("å¤„ç†å®Œæˆï¼")
    print(f"Markdownæ–‡æ¡£å·²ä¿å­˜è‡³: {output_md}")
    print('='*60)
    
    # æ˜¾ç¤ºæ‘˜è¦
    print("\nè¯†åˆ«æ‘˜è¦:")
    for result in all_results:
        print(f"  - {result['name']}: {result['rotation']} (æ–‡æœ¬é•¿åº¦: {len(result['content'])} å­—ç¬¦)")
    
    # ==================== ç”ŸæˆåŒå±‚PDF ====================
    print("\n" + "="*60)
    generate_pdf = input("æ˜¯å¦ç”ŸæˆåŒå±‚PDFï¼ˆå¯æœç´¢æ–‡æœ¬ï¼‰ï¼Ÿ(y/n): ").strip().lower()
    
    if generate_pdf == 'y':
        # æ”¶é›†å·²æ—‹è½¬çš„å›¾ç‰‡è·¯å¾„
        image_paths_for_pdf = []
        for result in all_results:
            # ä½¿ç”¨å·²ç»ä¿å­˜çš„æ­£ç¡®æ—‹è½¬è§’åº¦çš„å›¾ç‰‡
            rotation_name = result['rotation']
            img_path = os.path.join('images', f"{result['name']}_{rotation_name}.png")
            if os.path.exists(img_path):
                image_paths_for_pdf.append(img_path)
            else:
                print(f"âš  è­¦å‘Š: æ‰¾ä¸åˆ°å›¾ç‰‡ {img_path}")
        
        if image_paths_for_pdf:
            output_pdf = 'student_answers_searchable.pdf'
            success = pdf_generator.generate_double_layer_pdf(image_paths_for_pdf, output_pdf)
            if success:
                print(f"\nâœ“ åŒå±‚PDFç”ŸæˆæˆåŠŸï¼")
                print(f"  - æ–‡ä»¶è·¯å¾„: {output_pdf}")
                print(f"  - åŠŸèƒ½: å¯æœç´¢ã€å¯å¤åˆ¶æ–‡æœ¬")
        else:
            print("âŒ æ²¡æœ‰å¯ç”¨çš„å›¾ç‰‡ç”ŸæˆPDF")

